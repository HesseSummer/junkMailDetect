{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import\n",
    "0. 读取数据、矩阵计算\n",
    "--------\n",
    "1. 正则去标点等+大小写\n",
    "2. 空格分词+去停用词\n",
    "3. 词形统一\n",
    "3. tf-idf编码方式\n",
    "--------\n",
    "4. 模型：贝叶斯、决策树、随机森林、SVM、逻辑回归\n",
    "5. 分析：混淆矩阵、准确率预测、训练耗时\n",
    "6. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据集\n",
    "使用csv读取文本文件，得到二维列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...']\n",
      "['ham', 'Ok lar... Joking wif u oni...']\n",
      "['spam', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"获取原始数据\"\"\"\n",
    "file_path = '../smsspamcollection/SMSSpamCollection'\n",
    "smsFile = open(file_path, 'r', encoding='utf-8') ## 返回文件对象\n",
    "sms = csv.reader(smsFile, delimiter='\\t') ## 第一层：行列表；第二层：列列表\n",
    "sms = list(sms) \n",
    "smsFile.close()\n",
    "\"\"\"显示原始数据\"\"\"\n",
    "for line in sms[0:3]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理\n",
    "## 定义预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regUse(text):\n",
    "    text = re.sub(r\"[,.?!\\\":]\", '', text) # 去标点\n",
    "    text = re.sub(r\"'\\w*\\s\", ' ', text) # 去缩写\n",
    "    text = re.sub(r\"#?&.{1,3};\", '', text) # 去html符号\n",
    "    return text.lower()\n",
    "def sampleSeg(text):\n",
    "    tokens = [word for word in word_tokenize(text) if word not in stopwords.words('english') and len(word)>=3]\n",
    "    return tokens\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "def lemSeg(tokens):\n",
    "    res = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word, pos in pos_tag(tokens):\n",
    "        wordnet_pos = get_wordnet_pos(pos) or wordnet.NOUN\n",
    "        res.append(lemmatizer.lemmatize(word, pos=wordnet_pos))\n",
    "\n",
    "    return res\n",
    "def preprocess(text):\n",
    "    text = regUse(text)\n",
    "    tokens = sampleSeg(text)\n",
    "    tokens = lemSeg(tokens)\n",
    "    return tokens ## 返回的是单词列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实施预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预处理耗时:23.17s\n",
      "预处理后的结果示例：\n",
      "['jurong point crazy available bugis great world buffet cine get amore wat', 'lar joking wif oni', 'free entry wkly comp win cup final tkts 21st may 2005 text 87121 receive entry question std txt rate apply 08452810075over18']\n",
      "['ham', 'ham', 'spam']\n"
     ]
    }
   ],
   "source": [
    "sms_data = [] ## 每个元素是一个句子\n",
    "sms_label = [] ## 每个元素是一个字符串\"ham\"/\"spam\"\n",
    "start = time.perf_counter()\n",
    "for line in sms:\n",
    "    sms_data.append(\" \".join(preprocess(line[1])))\n",
    "    sms_label.append(line[0])\n",
    "elapsed = (time.perf_counter() - start)\n",
    "print(\"预处理耗时:{:.2f}s\".format(elapsed))\n",
    "\"\"\"显示预处理结果\"\"\"\n",
    "print(\"预处理后的结果示例：\")\n",
    "print(sms_data[0:3])\n",
    "print(sms_label[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 得到训练集、测试集\n",
    "## raw形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset规模:5572行, trainset规模:3900行, testset规模:1672行\n",
      "\n",
      "raw形式示例：\n",
      "['jurong point crazy available bugis great world buffet cine get amore wat']\n",
      "['ham']\n"
     ]
    }
   ],
   "source": [
    "size_dataset = len(sms_data)\n",
    "size_trainset = int(round(size_dataset*0.7))\n",
    "print('dataset规模:{}行, trainset规模:{}行, testset规模:{}行\\n'.format(size_dataset, size_trainset, size_dataset-size_trainset))\n",
    "\n",
    "x_train = np.array(sms_data[0:size_trainset])\n",
    "y_train = np.array(sms_label[0:size_trainset])\n",
    "\n",
    "x_test = np.array(sms_data[size_trainset+1: size_dataset])\n",
    "y_test = np.array(sms_label[size_trainset+1: size_dataset])\n",
    "\n",
    "print(\"raw形式示例：\")\n",
    "print(x_train[0:1])\n",
    "print(y_train[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "稀疏矩阵示例：\n",
      "  (0, 3696)\t0.31363210229069505\n",
      "  (0, 1368)\t0.348820693452981\n",
      "  (0, 738)\t0.344403438565091\n",
      "  (0, 981)\t0.3717663537353778\n",
      "  (0, 2182)\t0.252742012566388\n",
      "  (0, 5403)\t0.29960771122339475\n",
      "  (0, 980)\t0.4147806208896629\n",
      "  (0, 1152)\t0.36498744484823614\n",
      "  (0, 5222)\t0.25344224995737386\n",
      "稠密矩阵示例：\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer=TfidfVectorizer(min_df=2,ngram_range=(1,2),stop_words='english',strip_accents='unicode',norm='l2')\n",
    " \n",
    "x_train=vectorizer.fit_transform(x_train) #fit+标准化\n",
    "x_test=vectorizer.transform(x_test) #仅标准化即可\n",
    "\n",
    "print(\"稀疏矩阵示例：\")\n",
    "print(x_train[0:1])\n",
    "print(\"稠密矩阵示例：\")\n",
    "print(x_train[0:1].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始分类\n",
    "## 通用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(clf, name):\n",
    "    file_path = './' + name + '.pkl'\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "    print(name + \"模型保存成功\")\n",
    "        \n",
    "def get_model(name):\n",
    "    file_path = './' + name + '.pkl'\n",
    "    try:\n",
    "        with open(file_path,'rb') as f:\n",
    "          return pickle.load(f)\n",
    "    except EOFError: #捕获异常EOFError 后返回None\n",
    "        print('错误：尝试读取空文件')\n",
    "        return None   \n",
    "    \n",
    "def show_model(y_test, y_pred, name):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    print(name + '的混淆矩阵：')\n",
    "    print(cm)\n",
    "    print(name + '的分类结果：')\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB训练耗时:0.00s\n",
      "MultinomialNB的混淆矩阵：\n",
      "[[1439    4]\n",
      " [  64  164]]\n",
      "MultinomialNB的分类结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1443\n",
      "        spam       0.98      0.72      0.83       228\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1671\n",
      "   macro avg       0.97      0.86      0.90      1671\n",
      "weighted avg       0.96      0.96      0.96      1671\n",
      "\n",
      "MultinomialNB模型保存成功\n"
     ]
    }
   ],
   "source": [
    "\"\"\"训练\"\"\"\n",
    "start = time.perf_counter()\n",
    "clf = MultinomialNB().fit(x_train, y_train)\n",
    "elapsed = (time.perf_counter() - start)\n",
    "print(\"MultinomialNB训练耗时:{:.2f}s\".format(elapsed))\n",
    "\"\"\"预测\"\"\"\n",
    "y_nb_pred = clf.predict(x_test)\n",
    "\"\"\"结果显示\"\"\"\n",
    "show_model(y_test, y_nb_pred, \"MultinomialNB\")\n",
    "\"\"\"保存模型\"\"\"\n",
    "save_model(clf, \"MultinomialNB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree训练耗时:14.20s\n",
      "DecisionTree的混淆矩阵：\n",
      "[[1413   30]\n",
      " [  49  179]]\n",
      "DecisionTree的分类结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.98      0.97      1443\n",
      "        spam       0.86      0.79      0.82       228\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1671\n",
      "   macro avg       0.91      0.88      0.90      1671\n",
      "weighted avg       0.95      0.95      0.95      1671\n",
      "\n",
      "DecisionTree模型保存成功\n"
     ]
    }
   ],
   "source": [
    "\"\"\"训练\"\"\"\n",
    "start = time.perf_counter()\n",
    "clf = tree.DecisionTreeClassifier().fit(x_train.toarray(), y_train)\n",
    "elapsed = (time.perf_counter() - start)\n",
    "print(\"DecisionTree训练耗时:{:.2f}s\".format(elapsed))\n",
    "\"\"\"预测\"\"\"\n",
    "y_tree_pred = clf.predict(x_test.toarray())\n",
    "\"\"\"结果显示\"\"\"\n",
    "show_model(y_test, y_tree_pred, \"DecisionTree\")\n",
    "\"\"\"保存模型\"\"\"\n",
    "save_model(clf, \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest训练耗时:0.07s\n",
      "RandomForest的混淆矩阵：\n",
      "[[1438    5]\n",
      " [  53  175]]\n",
      "RandomForest的分类结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1443\n",
      "        spam       0.97      0.77      0.86       228\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1671\n",
      "   macro avg       0.97      0.88      0.92      1671\n",
      "weighted avg       0.97      0.97      0.96      1671\n",
      "\n",
      "RandomForest模型保存成功\n"
     ]
    }
   ],
   "source": [
    "\"\"\"训练\"\"\"\n",
    "start = time.perf_counter()\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(x_train, y_train)\n",
    "elapsed = (time.perf_counter() - start)\n",
    "print(\"RandomForest训练耗时:{:.2f}s\".format(elapsed))\n",
    "\"\"\"预测\"\"\"\n",
    "y_RF_pred = clf.predict(x_test)\n",
    "\"\"\"结果显示\"\"\"\n",
    "show_model(y_test, y_RF_pred, \"RandomForest\")\n",
    "\"\"\"保存模型\"\"\"\n",
    "save_model(clf, \"RandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC训练耗时:0.01s\n",
      "LinearSVC的混淆矩阵：\n",
      "[[1436    7]\n",
      " [  30  198]]\n",
      "LinearSVC的分类结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1443\n",
      "        spam       0.97      0.87      0.91       228\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1671\n",
      "   macro avg       0.97      0.93      0.95      1671\n",
      "weighted avg       0.98      0.98      0.98      1671\n",
      "\n",
      "LinearSVC模型保存成功\n"
     ]
    }
   ],
   "source": [
    "\"\"\"训练\"\"\"\n",
    "start = time.perf_counter()\n",
    "clf = LinearSVC().fit(x_train, y_train)\n",
    "elapsed = (time.perf_counter() - start)\n",
    "print(\"LinearSVC训练耗时:{:.2f}s\".format(elapsed))\n",
    "\"\"\"预测\"\"\"\n",
    "y_svm_pred = clf.predict(x_test)\n",
    "\"\"\"结果显示\"\"\"\n",
    "show_model(y_test, y_svm_pred, \"LinearSVC\")\n",
    "\"\"\"保存模型\"\"\"\n",
    "save_model(clf, \"LinearSVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非线性SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDsvm训练耗时:0.17s\n",
      "SGDsvm的混淆矩阵：\n",
      "[[1434    9]\n",
      " [  29  199]]\n",
      "SGDsvm的分类结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99      1443\n",
      "        spam       0.96      0.87      0.91       228\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1671\n",
      "   macro avg       0.97      0.93      0.95      1671\n",
      "weighted avg       0.98      0.98      0.98      1671\n",
      "\n",
      "SGDsvm模型保存成功\n"
     ]
    }
   ],
   "source": [
    "\"\"\"训练\"\"\"\n",
    "start = time.perf_counter()\n",
    "clf=SGDClassifier(alpha=0.0001,n_iter=50).fit(x_train, y_train)\n",
    "elapsed = (time.perf_counter() - start)\n",
    "print(\"SGDsvm训练耗时:{:.2f}s\".format(elapsed))\n",
    "\"\"\"预测\"\"\"\n",
    "y_SGDsvm_pred = clf.predict(x_test)\n",
    "\"\"\"结果显示\"\"\"\n",
    "show_model(y_test, y_SGDsvm_pred, \"SGDsvm\")\n",
    "\"\"\"保存模型\"\"\"\n",
    "save_model(clf, \"SGDsvm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDlog训练耗时:0.03s\n",
      "SGDlog的混淆矩阵：\n",
      "[[1436    7]\n",
      " [  37  191]]\n",
      "SGDlog的分类结果：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1443\n",
      "        spam       0.96      0.84      0.90       228\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1671\n",
      "   macro avg       0.97      0.92      0.94      1671\n",
      "weighted avg       0.97      0.97      0.97      1671\n",
      "\n",
      "SGDlog模型保存成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"训练\"\"\"\n",
    "start = time.perf_counter()\n",
    "clf=SGDClassifier(loss='log', alpha=0.0001,n_iter=50).fit(x_train, y_train)\n",
    "elapsed = (time.perf_counter() - start)\n",
    "print(\"SGDlog训练耗时:{:.2f}s\".format(elapsed))\n",
    "\"\"\"预测\"\"\"\n",
    "y_SGDlog_pred = clf.predict(x_test)\n",
    "\"\"\"结果显示\"\"\"\n",
    "show_model(y_test, y_SGDlog_pred, \"SGDlog\")\n",
    "\"\"\"保存模型\"\"\"\n",
    "save_model(clf, \"SGDlog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完成嘻嘻"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
